{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMoCd67EOV7qtcvfyFRJykM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Lucyy07/LSTM-learning/blob/main/test_lstm_modelOptimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7LiLF8WokggU"
      },
      "outputs": [],
      "source": [
        "import pandas_datareader.data as web\n",
        "import datetime\n",
        "start=datetime.datetime(2000,1,1)\n",
        "end=datetime.datetime(2021,9,1)\n",
        "df=web.DataReader('GOOGL','stooq',start,end)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 按日期排序\n",
        "df.dropna(inplace=True)  # 一定要先删除空值，否则神经网络计算不出损失值\n",
        "df.sort_index(inplace=True)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRavByiIlpu4",
        "outputId": "446e033b-7415-4b90-cec9-7566d4760a32"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Open      High       Low     Close      Volume\n",
            "Date                                                          \n",
            "2004-08-19    50.000    52.030    47.980    50.170  44703800.0\n",
            "2004-08-20    50.505    54.540    50.250    54.155  22857200.0\n",
            "2004-08-23    55.375    56.740    54.525    54.700  18274400.0\n",
            "2004-08-24    55.620    55.800    51.785    52.435  15262600.0\n",
            "2004-08-25    52.480    54.000    51.940    53.000   9197800.0\n",
            "...              ...       ...       ...       ...         ...\n",
            "2021-08-26  2835.000  2848.350  2827.140  2828.810   1030466.0\n",
            "2021-08-27  2833.050  2890.250  2829.940  2880.080   1439010.0\n",
            "2021-08-30  2888.000  2919.410  2883.260  2891.810   1221710.0\n",
            "2021-08-31  2902.940  2903.425  2885.620  2893.950   1122438.0\n",
            "2021-09-01  2900.000  2925.075  2897.670  2904.310   1096805.0\n",
            "\n",
            "[4289 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建要预测的标签\n",
        "# 预测时间\n",
        "# 删除，因为设置成了参数 pre_days=10\n",
        "def LSTM_data_precessing(df, mem_his_days, pre_days):\n",
        "  df['label']=df['Close'].shift(-pre_days)\n",
        "  print(df)\n",
        "  # 数据预处理：转换特征值\n",
        "  from sklearn.preprocessing import StandardScaler\n",
        "  scaler=StandardScaler()\n",
        "  scal_X=scaler.fit_transform(df.iloc[:,:-1])\n",
        "  #print(scal_X)\n",
        "  # 转换成以mem_his_days天为一个时间列的数据\n",
        "  # 删除此句，因为改成了参数  mem_his_days=10\n",
        "  from collections import deque\n",
        "  deq=deque(maxlen=mem_his_days)\n",
        "\n",
        "  X=[]\n",
        "  for i in scal_X:\n",
        "    deq.append(list(i))\n",
        "    if len(deq)==mem_his_days:\n",
        "      X.append(list(deq))\n",
        "\n",
        "  X_lately=X[-pre_days:]\n",
        "  X=X[:-pre_days]\n",
        "  #print(len(X))\n",
        "  #print(len(X_lately))\n",
        "  # 打包处理目标预测的值\n",
        "  y=df['label'].values[mem_his_days-1:-pre_days]\n",
        "  #print(len(y))\n",
        "  # 转换成numpy的数组类型\n",
        "  import numpy as np\n",
        "  x=np.array(X)\n",
        "  y=np.array(y)\n",
        "  #print(x.shape)\n",
        "  #print(y.shape)\n",
        "  return x,y,X_lately"
      ],
      "metadata": {
        "id": "bd-qdCNyl5NC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x,y,X_lately=LSTM_data_precessing(df, 5, 10)\n",
        "print(x.shape)\n",
        "print(x[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB_9ivJB5h4U",
        "outputId": "86d5693c-1eb4-4aef-caa0-9d386da308e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                Open      High       Low     Close      Volume   label\n",
            "Date                                                                  \n",
            "2004-08-19    50.000    52.030    47.980    50.170  44703800.0  50.755\n",
            "2004-08-20    50.505    54.540    50.250    54.155  22857200.0  50.005\n",
            "2004-08-23    55.375    56.740    54.525    54.700  18274400.0  50.790\n",
            "2004-08-24    55.620    55.800    51.785    52.435  15262600.0  51.150\n",
            "2004-08-25    52.480    54.000    51.940    53.000   9197800.0  51.155\n",
            "...              ...       ...       ...       ...         ...     ...\n",
            "2021-08-26  2835.000  2848.350  2827.140  2828.810   1030466.0     NaN\n",
            "2021-08-27  2833.050  2890.250  2829.940  2880.080   1439010.0     NaN\n",
            "2021-08-30  2888.000  2919.410  2883.260  2891.810   1221710.0     NaN\n",
            "2021-08-31  2902.940  2903.425  2885.620  2893.950   1122438.0     NaN\n",
            "2021-09-01  2900.000  2925.075  2897.670  2904.310   1096805.0     NaN\n",
            "\n",
            "[4289 rows x 6 columns]\n",
            "[[-1.08801034 -1.08523099 -1.08961219 -1.0866679   4.89712792]\n",
            " [-1.08705245 -1.08051426 -1.08526922 -1.07911793  2.09105043]\n",
            " [-1.0778149  -1.07638007 -1.07709028 -1.07808538  1.50241458]\n",
            " ...\n",
            " [ 4.29518661  4.30308185  4.33485023  4.29709095 -0.68791113]\n",
            " [ 4.32352522  4.27304322  4.33936538  4.30114538 -0.70066208]\n",
            " [ 4.31794854  4.31372739  4.36241946  4.3207734  -0.7039545 ]]\n",
            "4275\n",
            "10\n",
            "4275\n",
            "(4275, 5, 5)\n",
            "(4275,)\n",
            "(4275, 5, 5)\n",
            "[[-1.08801034 -1.08523099 -1.08961219 -1.0866679   4.89712792]\n",
            " [-1.08705245 -1.08051426 -1.08526922 -1.07911793  2.09105043]\n",
            " [-1.0778149  -1.07638007 -1.07709028 -1.07808538  1.50241458]\n",
            " [-1.07735017 -1.0781465  -1.08233246 -1.08237664  1.11556518]\n",
            " [-1.08330621 -1.08152902 -1.08203591 -1.08130619  0.33657445]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用循环多次测试最佳参数\n",
        "pre_days=10\n",
        "mem_days=[5,10,15]\n",
        "lstm_layers=[1,2,3]\n",
        "units=[16,32]\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense,Dropout\n",
        "for the_mem_days in mem_days:\n",
        "  for the_lstm_layers in lstm_layers:\n",
        "    for the_units in units:\n",
        "      filePath='{val_mape:.2f}_epochs_40_'+f'mem_{the_mem_days}_lstm{the_lstm_layers}_units_{the_units}'\n",
        "      checkPoint=ModelCheckpoint(filePath=filePath, save_weights_only=False,monitor='val_mape',mode='min',save_best_only=True)\n",
        "      x,y,X_lately=LSTM_data_precessing(df, the_mem_days, pre_days)\n",
        "      x_train, x_test, y_train, y_test=train_test_split(x,y,shuffle=False,test_size=0.1)\n",
        "      model=Sequential()\n",
        "      model.add(LSTM(the_units, input_shape=x.shape[1:],activation='relu',return_sequences=True))   # 此处input_shape只是指明输入的形式，并不是指输入数据\n",
        "      model.add(Dropout(0.1))\n",
        "\n",
        "      for i in range(the_lstm_layers):\n",
        "        model.add(LSTM(the_units,activation='relu',return_sequences=True))\n",
        "        model.add(Dropout(0.1))\n",
        "\n",
        "      # model.add(LSTM(10,activation='relu'))\n",
        "      # model.add(Dropout(0.1))\n",
        "\n",
        "      model.add(Dense(the_units, activation='relu'))\n",
        "      model.add(Dropout(0.1))\n",
        "\n",
        "      model.add(Dense(1))\n",
        "\n",
        "      model.compile(optimizer='adam',loss='mse',metrics=['mape'])\n",
        "\n",
        "      model.fit(x_train,y_train,batch_size=32,epochs=60,validation_data=(x_test,y_test))\n",
        "      print(filePath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOmRdu90cvTu",
        "outputId": "f43a0435-5701-4e91-8e1c-d4859d171c26"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{val_mape:.2f}_40_mem_5_lstm1_units_16\n",
            "{val_mape:.2f}_40_mem_5_lstm1_units_32\n",
            "{val_mape:.2f}_40_mem_5_lstm2_units_16\n",
            "{val_mape:.2f}_40_mem_5_lstm2_units_32\n",
            "{val_mape:.2f}_40_mem_5_lstm3_units_16\n",
            "{val_mape:.2f}_40_mem_5_lstm3_units_32\n",
            "{val_mape:.2f}_40_mem_10_lstm1_units_16\n",
            "{val_mape:.2f}_40_mem_10_lstm1_units_32\n",
            "{val_mape:.2f}_40_mem_10_lstm2_units_16\n",
            "{val_mape:.2f}_40_mem_10_lstm2_units_32\n",
            "{val_mape:.2f}_40_mem_10_lstm3_units_16\n",
            "{val_mape:.2f}_40_mem_10_lstm3_units_32\n",
            "{val_mape:.2f}_40_mem_15_lstm1_units_16\n",
            "{val_mape:.2f}_40_mem_15_lstm1_units_32\n",
            "{val_mape:.2f}_40_mem_15_lstm2_units_16\n",
            "{val_mape:.2f}_40_mem_15_lstm2_units_32\n",
            "{val_mape:.2f}_40_mem_15_lstm3_units_16\n",
            "{val_mape:.2f}_40_mem_15_lstm3_units_32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 划分训练集和测试集\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUfBTQVbry7V",
        "outputId": "465a9b2f-94d9-423a-c04f-c39633398c97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3843\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import LSTM,Dense,Dropout\n",
        "# model=Sequential()\n",
        "# model.add(LSTM(10, input_shape=x.shape[1:],activation='relu',return_sequences=True))   # 此处input_shape只是指明输入的形式，并不是指输入数据\n",
        "# model.add(Dropout(0.1))\n",
        "\n",
        "# model.add(LSTM(10,activation='relu',return_sequences=True))\n",
        "# model.add(Dropout(0.1))\n",
        "\n",
        "# model.add(LSTM(10,activation='relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "\n",
        "# model.add(Dense(10, activation='relu'))\n",
        "# model.add(Dropout(0.1))\n",
        "\n",
        "# model.add(Dense(1))\n",
        "\n",
        "# model.compile(optimizer='adam',loss='mse',metrics=['mape'])\n",
        "\n",
        "# model.fit(x_train,y_train,batch_size=32,epochs=60,validation_data=(x_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yU6KMsh0uuXG",
        "outputId": "a43e4330-e129-4d34-ef74-d92af8467e83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "121/121 [==============================] - 7s 21ms/step - loss: 455391.1875 - mape: 84.6283 - val_loss: 124986.2891 - val_mape: 44.8779\n",
            "Epoch 2/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 72153.1797 - mape: 33.8705 - val_loss: 17620.7637 - val_mape: 22.6395\n",
            "Epoch 3/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 53948.7305 - mape: 26.8533 - val_loss: 10271.9844 - val_mape: 16.7014\n",
            "Epoch 4/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 43130.2461 - mape: 23.7753 - val_loss: 26358.3555 - val_mape: 18.3589\n",
            "Epoch 5/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 42321.1250 - mape: 22.7552 - val_loss: 13123.5127 - val_mape: 16.3967\n",
            "Epoch 6/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 34005.4414 - mape: 21.4242 - val_loss: 11368.4414 - val_mape: 13.0096\n",
            "Epoch 7/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 35702.6328 - mape: 21.1776 - val_loss: 8769.4121 - val_mape: 12.1929\n",
            "Epoch 8/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 37130.4102 - mape: 21.3067 - val_loss: 11092.0352 - val_mape: 12.3443\n",
            "Epoch 9/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 33406.1719 - mape: 20.5690 - val_loss: 15142.5840 - val_mape: 14.9849\n",
            "Epoch 10/60\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 34927.9609 - mape: 19.4901 - val_loss: 9844.8945 - val_mape: 11.3379\n",
            "Epoch 11/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 31140.0371 - mape: 19.6109 - val_loss: 14175.0000 - val_mape: 13.7910\n",
            "Epoch 12/60\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 28215.3945 - mape: 18.6552 - val_loss: 13086.7871 - val_mape: 12.2044\n",
            "Epoch 13/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 31001.1699 - mape: 19.2724 - val_loss: 16894.7090 - val_mape: 13.2003\n",
            "Epoch 14/60\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 27229.5684 - mape: 18.9843 - val_loss: 17044.5039 - val_mape: 12.4483\n",
            "Epoch 15/60\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 22955.0137 - mape: 17.6748 - val_loss: 19370.9395 - val_mape: 16.0682\n",
            "Epoch 16/60\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 23261.7637 - mape: 17.3005 - val_loss: 12915.2988 - val_mape: 11.4213\n",
            "Epoch 17/60\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 21711.6641 - mape: 16.2910 - val_loss: 19575.0449 - val_mape: 12.3751\n",
            "Epoch 18/60\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 23777.1875 - mape: 16.4552 - val_loss: 10810.0576 - val_mape: 10.2661\n",
            "Epoch 19/60\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 20926.4902 - mape: 16.6844 - val_loss: 15886.1113 - val_mape: 10.8499\n",
            "Epoch 20/60\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 21215.6738 - mape: 16.0598 - val_loss: 7607.6904 - val_mape: 9.2319\n",
            "Epoch 21/60\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 20584.5234 - mape: 15.6262 - val_loss: 16218.0039 - val_mape: 10.7239\n",
            "Epoch 22/60\n",
            "121/121 [==============================] - 2s 18ms/step - loss: 22669.5879 - mape: 16.2544 - val_loss: 20582.1719 - val_mape: 12.4823\n",
            "Epoch 23/60\n",
            "121/121 [==============================] - 3s 23ms/step - loss: 19831.5879 - mape: 15.9324 - val_loss: 15802.7402 - val_mape: 13.5605\n",
            "Epoch 24/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 19998.6699 - mape: 15.5543 - val_loss: 16146.8164 - val_mape: 12.2006\n",
            "Epoch 25/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 19621.7344 - mape: 15.2519 - val_loss: 9330.5596 - val_mape: 9.3636\n",
            "Epoch 26/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 21181.2168 - mape: 15.6378 - val_loss: 20708.5410 - val_mape: 14.0789\n",
            "Epoch 27/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 19521.9551 - mape: 15.3806 - val_loss: 20955.5996 - val_mape: 14.1050\n",
            "Epoch 28/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 21075.2969 - mape: 15.8815 - val_loss: 23569.7520 - val_mape: 14.2327\n",
            "Epoch 29/60\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 19683.1797 - mape: 15.5783 - val_loss: 13086.3574 - val_mape: 11.0924\n",
            "Epoch 30/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 19689.0957 - mape: 15.0166 - val_loss: 23016.7969 - val_mape: 15.5404\n",
            "Epoch 31/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 16981.4043 - mape: 14.9551 - val_loss: 47959.6719 - val_mape: 18.5093\n",
            "Epoch 32/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 20400.0410 - mape: 15.7864 - val_loss: 17019.1836 - val_mape: 12.5147\n",
            "Epoch 33/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 20229.1914 - mape: 15.6187 - val_loss: 21309.5215 - val_mape: 13.8328\n",
            "Epoch 34/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 18820.3906 - mape: 15.0385 - val_loss: 23251.9062 - val_mape: 13.5748\n",
            "Epoch 35/60\n",
            "121/121 [==============================] - 2s 18ms/step - loss: 18124.9785 - mape: 14.7509 - val_loss: 12608.9775 - val_mape: 10.8277\n",
            "Epoch 36/60\n",
            "121/121 [==============================] - 2s 19ms/step - loss: 20773.7969 - mape: 15.0725 - val_loss: 16650.4121 - val_mape: 11.9106\n",
            "Epoch 37/60\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 20443.3887 - mape: 15.5659 - val_loss: 15618.1406 - val_mape: 11.5694\n",
            "Epoch 38/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 18017.3848 - mape: 15.4116 - val_loss: 15081.9111 - val_mape: 10.0884\n",
            "Epoch 39/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 16920.1426 - mape: 15.0150 - val_loss: 17833.9102 - val_mape: 12.5659\n",
            "Epoch 40/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 19044.1367 - mape: 14.3086 - val_loss: 24542.1367 - val_mape: 13.6191\n",
            "Epoch 41/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 18034.7930 - mape: 14.5546 - val_loss: 21646.3223 - val_mape: 13.1461\n",
            "Epoch 42/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 16987.0176 - mape: 14.4446 - val_loss: 33332.0039 - val_mape: 14.5149\n",
            "Epoch 43/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 18434.0977 - mape: 15.3741 - val_loss: 19621.4922 - val_mape: 12.3718\n",
            "Epoch 44/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 15798.8154 - mape: 14.0133 - val_loss: 22881.8477 - val_mape: 13.0829\n",
            "Epoch 45/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 19256.5879 - mape: 14.5389 - val_loss: 25708.5684 - val_mape: 12.6566\n",
            "Epoch 46/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 20393.3242 - mape: 15.1194 - val_loss: 20095.1680 - val_mape: 11.6988\n",
            "Epoch 47/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 16581.3281 - mape: 14.6205 - val_loss: 20673.6348 - val_mape: 12.5886\n",
            "Epoch 48/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 17684.6172 - mape: 14.5422 - val_loss: 9290.6182 - val_mape: 9.2874\n",
            "Epoch 49/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 18512.9941 - mape: 15.3704 - val_loss: 57098.1836 - val_mape: 22.4858\n",
            "Epoch 50/60\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 18720.3379 - mape: 14.8032 - val_loss: 13294.8467 - val_mape: 10.4859\n",
            "Epoch 51/60\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 19182.3477 - mape: 14.9921 - val_loss: 33670.3281 - val_mape: 16.3950\n",
            "Epoch 52/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 18705.6621 - mape: 14.8903 - val_loss: 24293.3262 - val_mape: 12.6812\n",
            "Epoch 53/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 16668.5723 - mape: 14.5321 - val_loss: 27164.1641 - val_mape: 14.3567\n",
            "Epoch 54/60\n",
            "121/121 [==============================] - 2s 16ms/step - loss: 16768.4609 - mape: 14.2531 - val_loss: 16599.6250 - val_mape: 10.9674\n",
            "Epoch 55/60\n",
            "121/121 [==============================] - 2s 15ms/step - loss: 17200.1445 - mape: 14.6093 - val_loss: 19796.1621 - val_mape: 10.8824\n",
            "Epoch 56/60\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 17227.3086 - mape: 14.5174 - val_loss: 46092.2148 - val_mape: 19.8163\n",
            "Epoch 57/60\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 18132.4551 - mape: 14.6976 - val_loss: 26194.1191 - val_mape: 13.4160\n",
            "Epoch 58/60\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 15539.7666 - mape: 14.3716 - val_loss: 28117.5684 - val_mape: 14.9264\n",
            "Epoch 59/60\n",
            "121/121 [==============================] - 2s 17ms/step - loss: 16469.1875 - mape: 13.9498 - val_loss: 22394.1445 - val_mape: 12.1917\n",
            "Epoch 60/60\n",
            "121/121 [==============================] - 2s 20ms/step - loss: 17322.2012 - mape: 14.3701 - val_loss: 37049.4023 - val_mape: 15.5320\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6994b875d0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}